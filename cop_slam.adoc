= COP SLAM

COP-SLAM son derece verimli bir kapalÄ± formda 3-D SLAM yaklaÅŸÄ±mÄ±dÄ±r, poz zincirlerini Ã§evrimiÃ§i duruma getirir ve g2o ile uyumludur. COP-SLAM demo programÄ± gÃ¶rsel odometri ve gÃ¶rÃ¼nÃ¼ÅŸ tabanlÄ± dÃ¶ngÃ¼ algÄ±lama ile elde edilen 60 kilometre poz zincir veri kÃ¼mesiyle birlikte gelir.

KapalÄ± form Ã‡evrimiÃ§i Pose-chain SLAM (COP-SLAM), Lie grup yapÄ±sÄ±nÄ± istifade ederek kapalÄ± zincirlerdeki poz zincirlerini etkili ve doÄŸru bir ÅŸekilde optimize eder.
Poz zincirleri, son derece seyrek poz grafiklerin belirli bir tÃ¼rÃ¼dÃ¼r ve doÄŸru gÃ¶rsel odometri ve gÃ¼venilir gÃ¶rÃ¼nÃ¼me dayalÄ± dÃ¶ngÃ¼ algÄ±lama gerÃ§ekleÅŸtiren Ã§aÄŸdaÅŸ SLAM Ã¶n uÃ§larÄ±nÄ±n bir Ã¼rÃ¼nÃ¼dÃ¼r.  
SÄ±k dÃ¶ngÃ¼ algÄ±lamanÄ±n istenmediÄŸi veya mÃ¼mkÃ¼n olmadÄ±ÄŸÄ± bÃ¼yÃ¼k Ã¶lÃ§ekli 3 boyutlu ortamlarda zorlu robot uygulamalarÄ± iÃ§in uygundurlar. KapalÄ±-Form Online Pose-chain SLAM tarafÄ±ndan elde edilen doÄŸruluÄŸun, en son yenilikÃ§i yinelemeli yÃ¶ntemlerle karÅŸÄ±laÅŸtÄ±rÄ±labilir olduÄŸu gÃ¶sterilmiÅŸtir; buna karÅŸÄ±lÄ±k Ã§Ã¶zÃ¼mÃ¼ hesaplamaya ihtiyaÃ§ duyan zaman bÃ¼yÃ¼klÃ¼kleri kadardÄ±r. Bu yeni SLAM tekniÄŸi, geniÅŸ bir robot uygulamalarÄ± ve hesaplama platformlarÄ± yelpazesiyle ilgilidir. COP-SLAM demo programÄ±nÄ±n harici baÄŸÄ±mlÄ±lÄ±klarÄ± yoktur ve 60 kilometre kullanÄ±ma hazÄ±r poz-zincir veri kÃ¼mesiyle birlikte gelir. DolayÄ±sÄ±yla, bu veri kÃ¼melerinde COP-SLAM'Ä±n oluÅŸturulmasÄ± ve Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± sÃ¼reci oldukÃ§a basittir.

image::images/0.jpg[]

= Ã–zet

Poz-grafik SLAM iÃ§in kapalÄ± formlu yeni bir Ã§Ã¶zÃ¼m sunulmuÅŸtur. YÃ¶rÃ¼nge bÃ¼kÃ¼lmesinin geniÅŸletilmiÅŸ bir versiyonunu kullanarak poz zincirleri adÄ± verilen Ã¶zel yapÄ±nÄ±n poz grafiklerini optimize eder. Ã‡Ã¶zÃ¼mÃ¼mÃ¼z, Ã¶n uÃ§larÄ± en yeni gÃ¶rsel odometri ve gÃ¶rÃ¼nÃ¼m tabanlÄ± dÃ¶ngÃ¼ algÄ±lama Ã¶zelliÄŸini kullanan sistemlerde kullanÄ±lmak Ã¼zere bir arka uÃ§ iyileÅŸtirici olarak tasarlanmÄ±ÅŸtÄ±r. KapalÄ± form yÃ¶ntemimizin ve son teknoloji yineleyici yÃ¶ntemlerin optimallik koÅŸullarÄ± tartÄ±ÅŸÄ±ldÄ±. Teorik farklÄ±lÄ±klarÄ±nÄ±n pratik Ã¶nemi simÃ¼le edilmiÅŸ ve gerÃ§ek veriler kullanÄ±larak yapÄ±lan kapsamlÄ± deneylerle araÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. 49 kilometrelik zorlayÄ±cÄ± binokÃ¼ler verilerle gÃ¶sterildi ki, kapalÄ± form Ã§Ã¶zÃ¼mÃ¼mÃ¼z tarafÄ±ndan elde edilen doÄŸruluk en son teknoloji yinelemeli Ã§Ã¶zÃ¼mlerle karÅŸÄ±laÅŸtÄ±rÄ±labilirken, Ã§Ã¶zÃ¼mÃ¼nÃ¼ hesaplamak iÃ§in gereken sÃ¼re 50 ila 200 kez faktÃ¶rdÃ¼r daha dÃ¼ÅŸÃ¼ktÃ¼r. Bu, yaklaÅŸÄ±mÄ±mÄ±zÄ± geniÅŸ bir uygulama yelpazesi ve hesaplama platformlarÄ±yla iliÅŸkilendirmektedir.

Genel grafiÄŸe dayalÄ± SLAM, poz-grafik SLAM ve poz zinciri SLAM arasÄ±ndaki kavramsal farklÄ±lÄ±klar Åekil 2'de gÃ¶sterilmektedir. 1. BirkaÃ§ yÄ±l Ã¶nce, SLAM Ã¶n uÃ§larÄ± tipik olarak, tek bir lazer mesafe tarayÄ±cÄ± ile dÃ¼zenli odometri (tekerlek dÃ¶nÃ¼ÅŸÃ¼ ve direksiyon aÃ§Ä±sÄ±) iÃ§eriyordu. Bu tÃ¼r Ã¶n uÃ§lar, arka uÃ§ iÃ§erisindeki poz ve yer iÅŸaretlerine gÃ¶re optimum hale getirme ihtiyacÄ±nÄ± yaratan nispeten hatalÄ± ilk tahminler Ã¼retmiÅŸtir (Åekil 1.a). SensÃ¶r teknolojisi ve iÅŸleme gÃ¼cÃ¼ yÄ±llar iÃ§inde ilerledikÃ§e, Ã¶n uÃ§lardaki yÃ¶ntemler daha doÄŸru baÅŸlangÄ±Ã§ tahminleri Ã¼retmeye baÅŸladÄ±. Bu, poz-grafik SLAM'Ä± popÃ¼ler bir teknik haline getiren SLAM arka ucuna verilen gereksinimleri dÃ¼ÅŸÃ¼rdÃ¼ (Åekil 1.b). Modern state-of-the-art visual odometry ve gÃ¶rÃ¼nÃ¼m tabanlÄ± dÃ¶ngÃ¼ saptama teknikleri, doÄŸruluk ve gÃ¼venilirlikte belirgin bir artÄ±ÅŸ gÃ¶stermiÅŸ ve modern bilgisayar donanÄ±mÄ±yla yÃ¼kÃ¼mlÃ¼dÃ¼r. Bu modern tekniklerin hata sapmasÄ± nispeten dÃ¼ÅŸÃ¼k olduÄŸundan, her zaman tutmak zorunlu deÄŸildir SLAM Ã¶n ucundaki mutlak pozlar arasÄ±ndaki tÃ¼m kenarlarÄ±n izini. Ortaya Ã§Ä±kan seyrek grafiÄŸi poz zinciri olarak adlandÄ±rÄ±rÄ±z (Åekil 1.c).

image::images/1.jpg[]

YukarÄ±daki gÃ¶rsel orijinal yÃ¶rÃ¼nge eÄŸilme algoritmasÄ±nÄ±n kavramsal gÃ¶sterimi. (A) 'da yeryÃ¼zÃ¼ndeki hakikat yÃ¶rÃ¼ngesinin mutlak pozlarÄ±, yeÅŸil Ã¼Ã§genlerle ve yeryÃ¼zÃ¼ndeki gerÃ§eÄŸe gÃ¶re, yeÅŸil kenarlarla gÃ¶receli poz yer deÄŸiÅŸtirmeleri ile tasvir edilmiÅŸtir. YÃ¶rÃ¼ngenin mutlak pozlarÄ± iÃ§in tahminler, turuncu Ã¼Ã§genlerle ve siyah kenarlarla gÃ¶reli poz yer deÄŸiÅŸtirmeleri iÃ§in olan tahminlerle gÃ¶sterilir. Belirli bir zamanda, sistem son mutlak pozu, yani (b) 'deki mavi Ã¼Ã§gen hakkÄ±nda daha doÄŸru bilgi alÄ±r. Ä°lk adÄ±m, (b) 'deki kÃ¼Ã§Ã¼k aÃ§Ä±k gri Ã¼Ã§genler tarafÄ±ndan gÃ¶sterilen gÃ¶receli poz gÃ¼ncellemelerini bulmak ve bu da son mutlak pozu arzu edilen son pozu, yani mavi Ã¼Ã§genin Ã¼zerine getirmektir. Bu gÃ¼ncellemelere yerel gÃ¼ncelleÅŸtirme denir. Ä°kinci adÄ±m ise, bu yerel gÃ¼ncellemeleri yÃ¶rÃ¼ngesine yayan dÃ¶nÃ¼ÅŸÃ¼mleri hesaplamaktÄ±r (c). Bu dÃ¶nÃ¼ÅŸÃ¼mlerin sonucu, (d) 'de kÃ¼Ã§Ã¼k siyah Ã¼Ã§genlerle gÃ¶sterilen daÄŸÄ±tÄ±lmÄ±ÅŸ gÃ¼ncellemelerdir. (D) 'de daÄŸÄ±tÄ±lmÄ±ÅŸ gÃ¼ncellemeler ile birlikte gÃ¶reli poz deplasmanlarÄ± kullanÄ±larak geliÅŸmiÅŸ bir yÃ¶rÃ¼nge hesaplanÄ±r. SonuÃ§, yÃ¶rÃ¼ngenin arzulanan mutlak pozlamada sona ermesidir.

Denemelerde kullanÄ±lan Ã¼Ã§ binokÃ¼ler veri kÃ¼mesinden Ã¶rnek resimler.

image::images/2.jpg[]

AÅŸaÄŸÄ±daki Ã¶rnekte Ã§eÅŸitli grafik tabanlÄ± SLAM resimlerinin Ã§izimi gÃ¶sterilmiÅŸtir. Genel grafik SLAM (a), poz-grafik SLAM (b), zincir-zincir SLAM (c). Ä°lk mutlak poz, yeÅŸil Ã¼Ã§gen ve ardÄ±ÅŸÄ±k mutlak pozlar turuncu Ã¼Ã§genlerle gÃ¶sterilir. Simgeler, mavi yÄ±ldÄ±zlarla gÃ¶sterilir. DÃ¼ÄŸÃ¼mler arasÄ±ndaki kenarlar (yani mutlak pozlar ve yer iÅŸaretleri) siyah Ã§izgilerle gÃ¶sterilir. (A) 'da, (b, c)' de yer iÅŸareti gÃ¶zlemleri, gÃ¶reli poz deplasmanlarÄ±nÄ± modelliyor. (C) 'de iki dÃ¶ngÃ¼ kapanÄ±ÅŸ kenarÄ± aÄŸÄ±r siyah Ã§izgilerle iÅŸaretlenmiÅŸtir.

image::images/3.jpg[]

YÃ¶rÃ¼nge bÃ¼kÃ¼mÃ¼ iÃ§in dÄ±ÅŸ (a) ve iÃ§ (b) kaynaÅŸma mekanizmalarÄ±. Son mutlak pozdaki belirsizlik, turuncu daire ve mavi daire tarafÄ±ndan arzulanan pozdaki belirsizlik ile gÃ¶sterilir. Son mutlak poz ile arzulanan pozun optimal kombinasyonu, (a) daki siyah Ã¼Ã§gen ile gÃ¶sterilir. (B) 'de yerel gÃ¼ncellemeler, son mutlak poz ve arzulanan pozun optimum kombinasyonu ile aynÄ± yere sahip olan bÃ¼yÃ¼k gri Ã¼Ã§gene biter.

image::images/4.jpg[]

Her bir veri seti iÃ§in 100 simÃ¼le edilmiÅŸ yÃ¶rÃ¼ngeden birinde elde edilen iki yÃ¶ntemin sonuÃ§larÄ±. (A) 'da Ã§iÃ§ek, (b) Ã§iÃ§ek, (c)' de 5 dÃ¶ngÃ¼ bulunan dÃ¼nya ve (d) 'de 25 dÃ¶ngÃ¼ bulunan dÃ¼nya gÃ¶sterilmektedir. Soldan saÄŸa: gerÃ§ek doÄŸruluk, simÃ¼le gÃ¶rsel odometri, COP-SLAM, G2O

image::images/5.jpg[]

SonuÃ§lar, her iki yÃ¶ntem iÃ§in Ã¼Ã§ boyutlu ve her Ã¼Ã§ Pittsburgh veri setinde Ã§izilmiÅŸtir. Pittsburgh-A (a), Pittsburgh-B (b) ve Pittsburgh-C (c) 'de gÃ¶sterilmiÅŸtir. Soldan saÄŸa: GPS doÄŸruluk, gÃ¶rsel odometri, COP-SLAM, G2O. Fayans boyutu 200 metredir.

image::images/6.jpg[]

COP-SLAM'Ä±n sonuÃ§larÄ±, Ã¼Ã§ Pittsburgh veri seti iÃ§in havadan ve topografik gÃ¶rÃ¼ntÃ¼lerin Ã¼stÃ¼ne Ã§izildi. Pittsburgh-A (a), Pittsburgh-B (b) ve Pittsburgh-C (c) 'de gÃ¶sterilmiÅŸtir. GPS esaslÄ± toprak gerÃ§eÄŸi yÃ¶rÃ¼ngeleri, COP-SLAM tarafÄ±ndan yeÅŸil olarak tahmin edilen kÄ±rmÄ±zÄ± ve yÃ¶rÃ¼ngeler halinde Ã§izilmiÅŸtir.

image::images/7.jpg[]

=PSEUDO KOD

**while running *do*
Get edge from SLAM front-end
if edge is a loop-closing edge then
Restrict computations to the Lie group of rotations.
R.1) Get 2
Dn
and compute 2
An
with Eq. 9.
R.2) Use Eq. 10, 3, 4 and 7 to compute the distributed updates.
R.3) Multiply  of each edge with the  of Eq. 13.
Recompute all absolute poses given the distributed updates.
Restrict computations to the Lie group of translations.
T.1) Get 2
Dn
and compute 2
An
with Eq. 9.
T.2) Use Eq. 10, 3, 4 and 7 to compute the distributed updates.
T.3) Multiply  of each edge with the  of Eq. 13.
Recompute all absolute poses given the distributed updates.
else
Add successive edge to end of pose-chain and compute new last
absolute pose
end if
end while

= KURULUM ve Ã‡ALIÅTIRMA

* <Dir> dizininde COP-SLAM paketini aÃ§tÄ±ÄŸÄ±nÄ±zÄ± veya teslim aldÄ±ÄŸÄ±nÄ± varsayarak,

* YÃ¼kleyin ve Ã§alÄ±ÅŸtÄ±rÄ±n
[source,java]
$ cd <dir>/build
$ cmake ../
$ make install
    

Bu, her ÅŸeyi kurar ve dizindeki her ÅŸeyi yÃ¼kler: <dir> / bin
(Bu nedenle sÃ¼per kullanÄ±cÄ± ayrÄ±calÄ±klarÄ± gerekmez)

* TÃ¼m 7 veri kÃ¼mesindeki COP-SLAM demo'sunu Ã§alÄ±ÅŸtÄ±rÄ±n

[source,java]
$ cd <dir>/bin
$ ./run_demo.sh

* TÃ¼m 7 veri kÃ¼mesi iÃ§in COP-SLAM sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirin

**1) **Octave (veya matlab) kullanÄ±n ve
[source,java]
$ octave
>> cd <dir>/bin
>> showG2OFiles

**2)**Veya g2o paketinin g2o_viewer sÃ¼rÃ¼mÃ¼nÃ¼ kullanÄ±n. Daha fazla bilgi iÃ§in openslam.org'daki g2o projesine bakÄ±n.



= AlgoritmalarÄ±n (MatematiÄŸin) Kod KarÅŸÄ±lÄ±klarÄ±

*[underline]#Algoritma#*

trajectory

A~t~=^t^âˆ~i=1~ M~i~ = M~1~ * M~2~ * M~3~... * M~t~ (1)

D~n~=A~n~*^n^âˆ~i=1~U~i~ (2)

U~t~ = I(^tâˆ’1^Î£~i=1~w~i~)^âˆ’1^I(^t^Î£~i=1~w~i~) (3)

I(Î±) = A~n~ * exp(Î± log(A~n~^âˆ’1^
* D~n~)) (4)

w~t~ =1/Ïƒ^2^~t~ ^n^Î£~i=1~1/Ïƒ^2^~i~ (5)

*[underline]#Kod#*


[source,]
----
// integrate trajectory upto current time-step
	    integrateChain( start, end, true );

	    // compute loop closure update
	    // only keep transaltion part
	    lcupdate = poseVector[end*4].inverse()*closeVector[n];
	    lcupdate.linear() << 1.0f,0.0f,0.0f,
				 0.0f,1.0f,0.0f,
				 0.0f,0.0f,1.0f;

	    // interpolate loop closure update into segments
	    normalizers = normalizers + interpolateTra( lcupdate, closeVector[n], n, start, end );

	    // apply the change of basis to the translation updates
	    cobChain( start, end, TRANSLATION );

	    // update the relative poses
	    updateChain( start, end, TRANSLATION );
	  }
	}
----

[source,]
----
//
// interpolate the loop closure update into segements
//
Eigen::Vector3f poseChain::interpolateRot( Eigen::Affine3f aupdate, Eigen::Affine3f adesired, const int aclosure, const int astart, const int aend )
{
   // helper variables
   Eigen::AngleAxisf aa;
   Eigen::Vector3f   normalizers(0.0f,0.0f,0.0f);
   Eigen::Affine3f   before;
   Eigen::Affine3f   after;
   Eigen::Affine3f   motion;
   Eigen::Affine3f   adesiredInv = adesired.inverse();
   float             rotNormalizer, sv;

   // convert rotation to tangent space at identity
   aa = aupdate.rotation();
   float angle = aa.angle();
   if( M_PI < angle )
     angle = angle - 2*M_PI;

   // get normalizer for weights  
   sv             = rotInfoVector.block( astart+1, 0, (aend-astart), 1 ).sum();
   normalizers[1] = ( 1.0f / ( 1.0f + (sv/rotCloseInfoVector(aclosure)) ) );
   rotNormalizer  = globalNormalizer * (sv + rotCloseInfoVector(aclosure));

   // compute updates
   int start     = (astart+1)*4; 
   int end       = aend*4;
   int nn        = (astart+1);
   for( int n = start; n <= end; n = n+4 )
   {

      // compute relative rotation
      motion.linear() = Eigen::AngleAxisf( angle*(rotInfoVector(nn,0)/rotNormalizer), aa.axis() ).toRotationMatrix();
      poseVector[n+3].linear() = adesired.linear()*motion.linear()*adesiredInv.linear();      
      nn++;     
   }        

   // return the normalizer for later use
   return normalizers;

}

//
// compute absolute poses from relative poses
//
void poseChain::integrateChain( const int astart, const int aend, const bool aidentity )
{

   // first abolute pose is identity
   Eigen::Affine3f temp;
   if( aidentity )
   {
     temp                 = poseVector[astart*4];
     poseVector[astart*4] = Eigen::Translation<float,3>(0.0f,0.0f,0.0f) * Eigen::Quaternion<float>(1.0f,0.0f,0.0f,0.0f);
   }

   // go through the relative poses
   int start = (astart+1)*4;
   int end   = aend*4;     
   EIGEN_ASM_COMMENT("begin");
   for( int n = start; n <= end; n = n+4 )
   {

      // and integrate the absolute pose chain
      poseVector[n] = poseVector[n-4]*poseVector[n+1];

   }
   EIGEN_ASM_COMMENT("end");

   // set back
   if( aidentity )
   {
     poseVector[astart*4] = temp;
   }

}

//
// compute absolute poses from relative poses
//
void poseChain::integrateChainNormalized( const int astart, const int aend, const bool normalize )
{

   // go through the relative poses
   int start = (astart+1)*4;
   int end   = aend*4;     
   EIGEN_ASM_COMMENT("begin");
   if( normalize )
   {
      // normalize relative poses
      for( int n = start; n <= end; n = n+4 )
      {
	  // normalize relative rotations
	  poseVector[n+1].linear() = poseVector[n+1].rotation();
      }            
   }

   // integrate
   for( int n = start; n <= end; n = n+4 )
   {
      // and integrate the absolute pose chain
      poseVector[n] = poseVector[n-4]*poseVector[n+1];      
   }

   EIGEN_ASM_COMMENT("end");

}
----


*[underline]#Algoritma#*

B=1/(1/Ïƒ^2^~A~~n~+1/Ïƒ^2^~D~~n~)

*[underline]#Kod#*

[source,]
----
void poseChain::updateChain( const int astart, const int aend, const int amethod )
{

   // go through the relative poses
   int start             = (astart+1)*4; 
   int end               = aend*4;
   int nn                = 0;
   float scaleCorrection = 1.0f;
   Eigen::Affine3f tmp;
   EIGEN_ASM_COMMENT("begin");
   if( amethod == BOTH )
   {
      for( int n = start; n <= end; n = n+4 )
      {

	  // update the relative poses
	  tmp             = poseVector[n+1]*poseVector[n+3];
	  poseVector[n+1] = tmp;

      }
   }
   else if( amethod == ROTATION )
   {
      for( int n = start; n <= end; n = n+4 )
      {	

	  // update the relative rotations
	  poseVector[n+1].linear() = poseVector[n+1].linear() * poseVector[n+3].linear();

      }
   }
   else if( amethod == TRANSLATION )
   {
      for( int n = start; n <= end; n = n+4 )
      {

	  // update the relative translations
	  poseVector[n+1].translation() = poseVector[n+1].translation() + poseVector[n+3].translation();

      }
   }
   else if( amethod == SCALE )
   {            

      for( int n = start; n <= end; n = n+4 )
      {

	  // update the relative translations
	  tmp                = poseVector[n+1];
	  scaleCorrection    = scaleCorrection*pow( scaleCloseFactor, scaleInfoVector(astart+1+nn)/scaleNormalizer );	
	  scaleVector(n/4,0) = scaleCorrection;
	  tmp.translation()  = scaleCorrection*poseVector[n+1].translation();
	  poseVector[n+1]    = tmp;	  
	  nn++;

      }            
      cout << "Loop-closure final scale correction: " << scaleCorrection << endl;

   } 
   EIGEN_ASM_COMMENT("end"); 
}
----
----
image::images/1.jpg[]ï¢½
